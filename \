#!/usr/bin/env python
import sys
import rospy
from std_msgs.msg import String
from qt_nuitrack_app.msg import Faces
from qt_robot_interface.srv import *
from qt_gesture_controller.srv import gesture_play


gesturePlay = rospy.ServiceProxy('/qt_robot/gesture/play', gesture_play)
em_index = 1
def sad_smile(em_index):
    if em_index == 0:
        emotionShow("QT/sad")
        rospy.sleep(2)
    elif em_index == 1:
        emotionShow("QT/calming_down")
        rospy.sleep(2)
def gesture():
    gesturePlay("my_gesture", 0)
def smile_nod():
    gesturePlay("my_gesture", 0)
    emotionShow("QT/calming_down")


    
    
if __name__ == '__main__':
    rospy.init_node('my_tutorial_node')
    rospy.loginfo("my_tutorial_node started!")

    emotionShow = rospy.ServiceProxy('/qt_robot/emotion/show', emotion_show)
    speech_pub = rospy.Publisher('/qt_robot/speech/say', String, queue_size=1)

    # define ros subscriber
    #rospy.Subscriber('/qt_nuitrack_app/faces', Faces, sad_smile)
    #sad_smile(em_index)
    #gesture()
    smile_nod()
    try:
        rospy.spin()
    except KeyboardInterrupt:
        pass

    rospy.loginfo("finsihed!")
